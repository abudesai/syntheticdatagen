{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NBEATS EXAMPLE\n",
    "\n",
    "https://subhayo.wordpress.com/2019/05/15/time-series-analysis-of-monthly-milk-production/\n",
    "\n",
    "It's a toy example to show how to do time series forecasting using N-Beats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from nbeats_pytorch.model import NBeatsNet\n",
    "from trainer_pytorch import save\n",
    "\n",
    "warnings.filterwarnings(action='ignore', message='Setting attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"2\"\n",
    "config = tf.compat.v1.ConfigProto() # Another Version: config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utils.\n",
    "def plot_scatter(*args, **kwargs):\n",
    "    plt.plot(*args, **kwargs)\n",
    "    plt.scatter(*args, **kwargs)\n",
    "\n",
    "\n",
    "# simple batcher.\n",
    "def data_generator(x, y, size):\n",
    "    assert len(x) == len(y)\n",
    "    batches = []\n",
    "    for ii in range(0, len(x), size):\n",
    "        batches.append((x[ii:ii + size], y[ii:ii + size]))\n",
    "    for batch in batches:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    forecast_length = 5\n",
    "    backcast_length = 3 * forecast_length\n",
    "    batch_size = 10  # greater than 4 for viz\n",
    "\n",
    "    milk = pd.read_csv('data/milk.csv', index_col=0, parse_dates=True)\n",
    "    print(milk.head())\n",
    "    milk = milk.values.flatten()  # just keep np array here for simplicity.\n",
    "\n",
    "    # data backcast/forecast generation.\n",
    "    x, y = [], []\n",
    "    for epoch in range(backcast_length, len(milk) - forecast_length):\n",
    "        x.append(milk[epoch - backcast_length:epoch])\n",
    "        y.append(milk[epoch:epoch + forecast_length])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # split train/test.\n",
    "    c = int(len(x) * 0.8)\n",
    "    x_train, y_train = x[:c], y[:c]\n",
    "    x_test, y_test = x[c:], y[c:]\n",
    "\n",
    "    # normalization.\n",
    "    norm_constant = np.max(x_train)\n",
    "    x_train, y_train = x_train / norm_constant, y_train / norm_constant\n",
    "    x_test, y_test = x_test / norm_constant, y_test / norm_constant\n",
    "\n",
    "    # model\n",
    "    net = NBeatsNet(\n",
    "        stack_types=(NBeatsNet.GENERIC_BLOCK, NBeatsNet.GENERIC_BLOCK),\n",
    "        forecast_length=forecast_length,\n",
    "        backcast_length=backcast_length,\n",
    "        hidden_layer_units=128,\n",
    "    )\n",
    "    optimiser = optim.Adam(lr=1e-4, params=net.parameters())\n",
    "\n",
    "    grad_step = 0\n",
    "    for epoch in range(1000):\n",
    "        # train.\n",
    "        net.train()\n",
    "        train_loss = []\n",
    "        for x_train_batch, y_train_batch in data_generator(x_train, y_train, batch_size):\n",
    "            grad_step += 1\n",
    "            optimiser.zero_grad()\n",
    "            _, forecast = net(torch.tensor(x_train_batch, dtype=torch.float).to(net.device))\n",
    "            loss = F.mse_loss(forecast, torch.tensor(y_train_batch, dtype=torch.float).to(net.device))\n",
    "            train_loss.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "        train_loss = np.mean(train_loss)\n",
    "\n",
    "        # test.\n",
    "        net.eval()\n",
    "        _, forecast = net(torch.tensor(x_test, dtype=torch.float))\n",
    "        test_loss = F.mse_loss(forecast, torch.tensor(y_test, dtype=torch.float)).item()\n",
    "        p = forecast.detach().numpy()\n",
    "        if epoch % 100 == 0:\n",
    "            subplots = [221, 222, 223, 224]\n",
    "            plt.figure(1)\n",
    "            for plot_id, i in enumerate(np.random.choice(range(len(x_test)), size=4, replace=False)):\n",
    "                ff, xx, yy = p[i] * norm_constant, x_test[i] * norm_constant, y_test[i] * norm_constant\n",
    "                plt.subplot(subplots[plot_id])\n",
    "                plt.grid()\n",
    "                plot_scatter(range(0, backcast_length), xx, color='b')\n",
    "                plot_scatter(range(backcast_length, backcast_length + forecast_length), yy, color='g')\n",
    "                plot_scatter(range(backcast_length, backcast_length + forecast_length), ff, color='r')\n",
    "            plt.show()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                save(net, optimiser, grad_step)\n",
    "            print(f'epoch = {str(epoch).zfill(4)}, '\n",
    "                  f'grad_step = {str(grad_step).zfill(6)}, '\n",
    "                  f'tr_loss (epoch) = {1000 * train_loss:.3f}, '\n",
    "                  f'te_loss (epoch) = {1000 * test_loss:.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
