{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "488e46a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nbeats_keras.model import NBeatsNet as NBeatsKeras\n",
    "warnings.filterwarnings(action='ignore', message='Setting attributes')\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc69fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "config = tf.compat.v1.ConfigProto() # Another Version: config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932cd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utils.\n",
    "def plot_scatter(*args, **kwargs):\n",
    "    plt.plot(*args, **kwargs)\n",
    "    plt.scatter(*args, **kwargs)\n",
    "\n",
    "\n",
    "# simple batcher.\n",
    "def data_generator(x, y, size):\n",
    "    assert len(x) == len(y)\n",
    "    batches = []\n",
    "    for ii in range(0, len(x), size):\n",
    "        batches.append((x[ii:ii + size], y[ii:ii + size]))\n",
    "    for batch in batches:\n",
    "        yield batch\n",
    "\n",
    "        \n",
    "def MinMaxScaler(data):\n",
    "  \"\"\"Min Max normalizer.\n",
    "  \n",
    "  Args:\n",
    "    - data: original data\n",
    "  \n",
    "  Returns:\n",
    "    - norm_data: normalized data\n",
    "  \"\"\"\n",
    "  numerator = data - np.min(data, 0)\n",
    "  denominator = np.max(data, 0) - np.min(data, 0)\n",
    "  norm_data = numerator / (denominator + 1e-7)\n",
    "  return norm_data\n",
    "        \n",
    "# to load real data        \n",
    "def real_data_loading (data_name, seq_len):\n",
    "  \"\"\"Load and preprocess real-world datasets.\n",
    "  \n",
    "  Args:\n",
    "    - data_name: stock or energy\n",
    "    - seq_len: sequence length\n",
    "    \n",
    "  Returns:\n",
    "    - data: preprocessed data.\n",
    "  \"\"\"  \n",
    "\n",
    "  assert data_name in ['stock','energy','abu']\n",
    "\n",
    "  if data_name == 'stock':\n",
    "    ori_data = np.loadtxt('/data/home/stufs1/zuwang/dg21/TimeGAN/data/stock_data.csv', delimiter = \",\",skiprows = 1)\n",
    "  elif data_name == 'energy':\n",
    "      ori_data = np.loadtxt('/data/home/stufs1/zuwang/dg21/TimeGAN/data/energy_data.csv', delimiter = \",\",skiprows = 1)\n",
    "        \n",
    "  # Flip the data to make chronological data\n",
    "  ori_data = ori_data[::-1]\n",
    "  # Normalize the data\n",
    "  ori_data = MinMaxScaler(ori_data)\n",
    "    \n",
    "  # Preprocess the dataset\n",
    "  temp_data = []    \n",
    "  # Cut data by sequence length\n",
    "  for i in range(0, len(ori_data) - seq_len):\n",
    "    _x = ori_data[i:i + seq_len]\n",
    "    temp_data.append(_x)\n",
    "        \n",
    "  # Mix the datasets (to make it similar to i.i.d)\n",
    "  idx = np.random.permutation(len(temp_data))    \n",
    "  data = []\n",
    "  for i in range(len(temp_data)):\n",
    "    data.append(temp_data[idx[i]])\n",
    "    \n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152cb80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synthetic data shape: (1048551, 24, 6)\n"
     ]
    }
   ],
   "source": [
    "# load the generated data -- Abu's data\n",
    "src_path = \"/data/home/stufs1/zuwang/dg21/TimeGAN/\"\n",
    "filename = \"abhu_data.csv\"\n",
    "\n",
    "seq_len = 24\n",
    "syn_data = np.loadtxt(os.path.join(src_path, filename), delimiter = \",\",skiprows = 1)\n",
    "syn_data = MinMaxScaler(syn_data)\n",
    "\n",
    "temp_data = []    \n",
    "for i in range(0, len(syn_data) - seq_len):\n",
    "    _x = syn_data[i:i + seq_len]\n",
    "    temp_data.append(_x)\n",
    "\n",
    "# Mix the datasets (to make it similar to i.i.d)\n",
    "idx = np.random.permutation(len(temp_data))    \n",
    "data = []\n",
    "for i in range(len(temp_data)):\n",
    "    data.append(temp_data[idx[i]])\n",
    "\n",
    "data = np.asarray(data)\n",
    "syn_data = data[:,:,:6] #cut and only use the first 6 columns\n",
    "print(\"synthetic data shape:\", syn_data.shape) # (no, seq_len, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b05c332a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real data shape: (3661, 24, 6)\n"
     ]
    }
   ],
   "source": [
    "# load the real data -- TimeGAN\n",
    "data_name = \"stock\"\n",
    "seq_len = 24\n",
    "ori_data = real_data_loading(data_name, seq_len) # \n",
    "ori_data = np.asarray(ori_data)\n",
    "print(\"real data shape:\", ori_data.shape) # (no, seq_len, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24594c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syn_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84794370",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size is: 3661\n"
     ]
    }
   ],
   "source": [
    "num_samples, time_steps, input_dim, output_dim = 1048551, 24, 6, 6\n",
    "backend = NBeatsKeras(\n",
    "        input_dim=input_dim,\n",
    "        backcast_length=19, forecast_length=5,\n",
    "        stack_types=(NBeatsKeras.GENERIC_BLOCK, NBeatsKeras.GENERIC_BLOCK),\n",
    "        nb_blocks_per_stack=2, thetas_dim=(4, 4), share_weights_in_stack=True,\n",
    "        hidden_layer_units=64\n",
    "    )\n",
    "\n",
    "# Definition of the objective function and the optimizer.\n",
    "backend.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "forecast_length = 5\n",
    "backcast_length = 19\n",
    "\n",
    "#### Stock-TimeGAN\n",
    "# x: data backcast/y: forecast generation.\n",
    "\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for i in range(len(syn_data)):\n",
    "    x_train.append(syn_data[i][:19,:])\n",
    "    y_train.append(syn_data[i][19:,:])\n",
    "\n",
    "x_test, y_test = [], []\n",
    "for i in range(len(ori_data)):\n",
    "    x_test.append(ori_data[i][:19,:])\n",
    "    y_test.append(ori_data[i][19:,:])\n",
    "\n",
    "\n",
    "'''\n",
    "x_train, y_train = [], []\n",
    "for i in range(len(syn_data)):\n",
    "    for epoch in range(backcast_length, len(syn_data[i]) - forecast_length):\n",
    "        x_train.append(syn_data[i][epoch - backcast_length:epoch])\n",
    "        y_train.append(syn_data[i][epoch:epoch + forecast_length])\n",
    "\n",
    "x_test, y_test = [], []\n",
    "for i in range(len(ori_data)):\n",
    "    for epoch in range(backcast_length, len(ori_data[i]) - forecast_length):\n",
    "        x_test.append(ori_data[i][epoch - backcast_length:epoch])\n",
    "        y_test.append(ori_data[i][epoch:epoch + forecast_length])\n",
    "'''\n",
    "\n",
    "# normalization.\n",
    "norm_constant = np.max(x_train)\n",
    "x_train, y_train = x_train / norm_constant, y_train / norm_constant\n",
    "x_test, y_test = x_test / norm_constant, y_test / norm_constant\n",
    "test_size = len(x_test)\n",
    "print(\"test_size is:\", test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f94090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1048551, 19, 6), (1048551, 5, 6), (3661, 19, 6), (3661, 5, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the model data shape\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fb6a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/1000\n",
      "8192/8192 [==============================] - 79s 7ms/step - loss: 0.0909 - val_loss: 0.1890\n",
      "Epoch 2/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0897 - val_loss: 0.1901\n",
      "Epoch 3/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0896 - val_loss: 0.1897\n",
      "Epoch 4/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0894 - val_loss: 0.1918\n",
      "Epoch 5/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0893 - val_loss: 0.1914\n",
      "Epoch 6/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0893 - val_loss: 0.1897\n",
      "Epoch 7/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0892 - val_loss: 0.1898\n",
      "Epoch 8/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0892 - val_loss: 0.1907\n",
      "Epoch 9/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0892 - val_loss: 0.1917\n",
      "Epoch 10/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0892 - val_loss: 0.1904\n",
      "Epoch 11/1000\n",
      "8192/8192 [==============================] - 54s 7ms/step - loss: 0.0891 - val_loss: 0.1960\n",
      "Epoch 12/1000\n",
      "8192/8192 [==============================] - 52s 6ms/step - loss: 0.0891 - val_loss: 0.1876\n",
      "Epoch 13/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0891 - val_loss: 0.1905\n",
      "Epoch 14/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0891 - val_loss: 0.1932\n",
      "Epoch 15/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0891 - val_loss: 0.1982\n",
      "Epoch 16/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0891 - val_loss: 0.2000\n",
      "Epoch 17/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.2025\n",
      "Epoch 18/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1992\n",
      "Epoch 19/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1962\n",
      "Epoch 20/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.2045\n",
      "Epoch 21/1000\n",
      "8192/8192 [==============================] - 52s 6ms/step - loss: 0.0890 - val_loss: 0.2166\n",
      "Epoch 22/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1967\n",
      "Epoch 23/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1995\n",
      "Epoch 24/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1931\n",
      "Epoch 25/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1953\n",
      "Epoch 26/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1989\n",
      "Epoch 27/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1961\n",
      "Epoch 28/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1955\n",
      "Epoch 29/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1932\n",
      "Epoch 30/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1990\n",
      "Epoch 31/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1962\n",
      "Epoch 32/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.2044\n",
      "Epoch 33/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1975\n",
      "Epoch 34/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2011\n",
      "Epoch 35/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0890 - val_loss: 0.1925\n",
      "Epoch 36/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2002\n",
      "Epoch 37/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1991\n",
      "Epoch 38/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2023\n",
      "Epoch 39/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1962\n",
      "Epoch 40/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2025\n",
      "Epoch 41/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2005\n",
      "Epoch 42/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2012\n",
      "Epoch 43/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1978\n",
      "Epoch 44/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1989\n",
      "Epoch 45/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1924\n",
      "Epoch 46/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1948\n",
      "Epoch 47/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1918\n",
      "Epoch 48/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1894\n",
      "Epoch 49/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1980\n",
      "Epoch 50/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1923\n",
      "Epoch 51/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1913\n",
      "Epoch 52/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1981\n",
      "Epoch 53/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1938\n",
      "Epoch 54/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1952\n",
      "Epoch 55/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1924\n",
      "Epoch 56/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1979\n",
      "Epoch 57/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1982\n",
      "Epoch 58/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2026\n",
      "Epoch 59/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2057\n",
      "Epoch 60/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1965\n",
      "Epoch 61/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1950\n",
      "Epoch 62/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1974\n",
      "Epoch 63/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0888 - val_loss: 0.1950\n",
      "Epoch 64/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2005\n",
      "Epoch 65/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2007\n",
      "Epoch 66/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2023\n",
      "Epoch 67/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1980\n",
      "Epoch 68/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0888 - val_loss: 0.1934\n",
      "Epoch 69/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1929\n",
      "Epoch 70/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0888 - val_loss: 0.2000\n",
      "Epoch 71/1000\n",
      "8192/8192 [==============================] - 50s 6ms/step - loss: 0.0889 - val_loss: 0.1987\n",
      "Epoch 72/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0888 - val_loss: 0.2008\n",
      "Epoch 73/1000\n",
      "8192/8192 [==============================] - 50s 6ms/step - loss: 0.0888 - val_loss: 0.1978\n",
      "Epoch 74/1000\n",
      "8192/8192 [==============================] - 50s 6ms/step - loss: 0.0888 - val_loss: 0.1987\n",
      "Epoch 75/1000\n",
      "8192/8192 [==============================] - 50s 6ms/step - loss: 0.0889 - val_loss: 0.2041\n",
      "Epoch 76/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1951\n",
      "Epoch 77/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.2016\n",
      "Epoch 78/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0888 - val_loss: 0.1961\n",
      "Epoch 79/1000\n",
      "8192/8192 [==============================] - 51s 6ms/step - loss: 0.0889 - val_loss: 0.1994\n",
      "Epoch 80/1000\n",
      "8192/8192 [==============================] - 50s 6ms/step - loss: 0.0888 - val_loss: 0.1992\n",
      "Epoch 81/1000\n",
      "2455/8192 [=======>......................] - ETA: 35s - loss: 0.0888"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "print('Training...')\n",
    "backend.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=1000, batch_size=128)\n",
    "\n",
    "# Save the model for later.\n",
    "backend.save('n_beats_model_abu.h5')\n",
    "\n",
    "# Predict on the testing set (forecast).\n",
    "predictions_forecast = backend.predict(x_test)\n",
    "print(\"the prediction_forecast shape is:\", predictions_forecast.shape) #shape: (30, 5, 1)\n",
    "#np.testing.assert_equal(predictions_forecast.shape, (test_size, backend.forecast_length, output_dim))\n",
    "\n",
    "# Predict on the testing set (backcast).\n",
    "predictions_backcast = backend.predict(x_test, return_backcast=True)\n",
    "print(\"the prediction_backcast shape is:\", predictions_backcast.shape) #shape: (30, 15, 1)\n",
    "#np.testing.assert_equal(predictions_backcast.shape, (test_size, backend.backcast_length, output_dim))\n",
    "\n",
    "# Load the model.\n",
    "model_2 = NBeatsKeras.load('n_beats_model_abu.h5')\n",
    "predicts = model_2.predict(x_test)\n",
    "print(\"the reloaded prediction_shape is:\", predicts.shape) #shape: (30, 5, 1)\n",
    "#np.testing.assert_almost_equal(predictions_forecast, model_2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38609c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = len(x_test)\n",
    "\n",
    "MAE_temp = 0.0\n",
    "MSE_temp = 0.0\n",
    "\n",
    "for i in range(num_sample):\n",
    "    MAE_temp = MAE_temp + mean_absolute_error(y_test[i], predicts[i])\n",
    "    MSE_temp = MSE_temp + mean_squared_error(y_test[i], predicts[i])\n",
    "\n",
    "predictive_score_mae = MAE_temp/num_sample\n",
    "predictive_score_mse = MSE_temp/num_sample\n",
    "print(\"predictive_score_mae:\", predictive_score_mae)\n",
    "print(\"predictive_score_mse:\", predictive_score_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots = [221, 222, 223, 224]\n",
    "plt.figure(1)\n",
    "for plot_id, i in enumerate(np.random.choice(range(len(x_test)), size=4, replace=False)):\n",
    "    p1 = np.expand_dims(predicts[i][:,0], axis=-1)\n",
    "    x1 = np.expand_dims(x_test[i][:,0], axis=-1)\n",
    "    y1 = np.expand_dims(y_test[i][:,0], axis=-1)\n",
    "    ff, xx, yy = p1 * norm_constant, x1 * norm_constant, y1 * norm_constant\n",
    "    plt.subplot(subplots[plot_id])\n",
    "    plt.grid()\n",
    "    plot_scatter(range(0, backcast_length), xx, color='b')\n",
    "    plot_scatter(range(backcast_length, backcast_length + forecast_length), yy, color='g')\n",
    "    plot_scatter(range(backcast_length, backcast_length + forecast_length), ff, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e22f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
