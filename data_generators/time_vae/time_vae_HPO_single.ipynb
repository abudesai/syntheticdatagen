{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import sys, os\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np , pandas as pd\n",
    "import time\n",
    "import joblib\n",
    "import random\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.plots import plot_objective, plot_evaluations\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import Optimizer # for the optimization\n",
    "from joblib import Parallel, delayed # for the parallelization\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from vae_dense_model import VariationalAutoencoderDense as VAE_Dense\n",
    "from vae_conv_model import VariationalAutoencoderConv as VAE_Conv\n",
    "from vae_conv_I_model import VariationalAutoencoderConvInterpretable as VAE_ConvI\n",
    "from config import config as cfg\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../../data/processed_orig_data/\"\n",
    "output_dir = \"../../data/generated_data/\"\n",
    "model_dir = './model/'\n",
    "log_dir = './log/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seeds(seed_value):   \n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_valid_split(data, valid_perc):\n",
    "    N = data.shape[0]\n",
    "    N_train = int(N * (1 - valid_perc))\n",
    "    N_valid = N - N_train\n",
    "\n",
    "    # shuffle data, just in case\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    # train, valid split \n",
    "    train_data = data[:N_train]\n",
    "    valid_data = data[N_train:]\n",
    "    return train_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_train_valid_data(train_data, valid_data, scaling_method):         \n",
    "    if scaling_method == 'minmax':    \n",
    "        scaler = utils.MinMaxScaler( )  \n",
    "    elif scaling_method == 'standard': \n",
    "        raise NotImplementedError(f'Scaling method {scaling_method} not implemented')\n",
    "    elif scaling_method == 'yeojohnson':\n",
    "        raise NotImplementedError(f'Scaling method {scaling_method} not implemented')\n",
    "    else:         \n",
    "        raise NotImplementedError(f'Scaling method {scaling_method} not implemented')       \n",
    "          \n",
    "    scaled_train_data = scaler.fit_transform(train_data)\n",
    "    scaled_valid_data = scaler.transform(valid_data)\n",
    "    return scaled_train_data, scaled_valid_data, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main VAE Train and Evaluate Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data, latent_dim, n_layer1_in_20s, n_layer2_in_25s, n_layer3_in_50s, epochs = 100):\n",
    "    \n",
    "    _, T, D = train_data.shape\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # Instantiate the VAE\n",
    "    vae = VAE_ConvI( seq_len=T,  \n",
    "                    feat_dim = D, \n",
    "                    latent_dim = int(latent_dim), \n",
    "                    hidden_layer_sizes=[ \n",
    "                        int(n_layer1_in_20s*20), \n",
    "                        int(n_layer2_in_25s*25),\n",
    "                        int(n_layer3_in_50s*50)], \n",
    "                # trend_poly=1, \n",
    "                # num_gen_seas=1,\n",
    "                # custom_seas = [ (7, 1)] ,     # list of tuples of (num_of_seasons, len_per_season)\n",
    "                use_residual_conn = True\n",
    "        )\n",
    "\n",
    "    vae.compile(optimizer=Adam())\n",
    "    # vae.summary() ; sys.exit()\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    # Train the VAE\n",
    "    early_stop_loss = 'loss'\n",
    "    early_stop_callback = EarlyStopping(monitor=early_stop_loss, min_delta = 1e-1, patience=50) \n",
    "    reduceLR = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=10)\n",
    "\n",
    "    history = vae.fit(\n",
    "        train_data, \n",
    "        batch_size = 32,\n",
    "        epochs=epochs,\n",
    "        shuffle = True,\n",
    "        callbacks=[early_stop_callback, reduceLR],\n",
    "        verbose = 0\n",
    "    )\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------\n",
    "    return vae, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, valid_data): \n",
    "    return model.evaluate(valid_data, verbose = 0, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO Using Scikit Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 2, 4, 4, 'minmax']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the hyperparameter space\n",
    "param_grid = [\n",
    "    Integer(2, 10, name=\"latent_dim\"),\n",
    "    Integer(1, 5, name=\"n_layer1_in_20s\"),\n",
    "    Integer(1, 8, name=\"n_layer2_in_25s\"),\n",
    "    Integer(1, 8, name=\"n_layer3_in_50s\"),\n",
    "    Categorical(['minmax'], name=\"scaling_method\"),\n",
    "]\n",
    "\n",
    "default_parameters = [\n",
    "    8,              # latent_dim\n",
    "    2,             # n_layer1_in_20s \n",
    "    4,            # n_layer2_in_25s\n",
    "    4,            # n_layer3_in_50s\n",
    "    'minmax'        # scaling_method\n",
    "]\n",
    "\n",
    "default_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective for HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_named_args(param_grid)\n",
    "def objective(\n",
    "            latent_dim,\n",
    "            n_layer1_in_20s,\n",
    "            n_layer2_in_25s,\n",
    "            n_layer3_in_50s,\n",
    "            scaling_method,\n",
    "        ):\n",
    "\n",
    "    global trial_num\n",
    "    global best_loss\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    # Print the hyper-parameters.   \n",
    "    print('-------------------------------------------')\n",
    "    print(f'trial_num: {trial_num}')\n",
    "    \n",
    "    print(f'latent_dim: {latent_dim}')\n",
    "    print(f'n_layer1_in_20s: {n_layer1_in_20s}')\n",
    "    print(f'n_layer2_in_25s: {n_layer2_in_25s}')\n",
    "    print(f'n_layer3_in_50s: {n_layer3_in_50s}')\n",
    "    print(f'scaling_method: {scaling_method}')   \n",
    "    print()   \n",
    "\n",
    "    trial_num += 1    \n",
    "    \n",
    "\n",
    "    losses = []\n",
    "    for train_index, valid_index in kf.split(data):  \n",
    "        \n",
    "        # grab train/test data using kf indexes\n",
    "        train_data, valid_data = data[train_index], data[valid_index]\n",
    "        \n",
    "        # scale data \n",
    "        scaled_train_data, scaled_valid_data, scaler = scale_train_valid_data(train_data, valid_data, scaling_method)\n",
    "        \n",
    "        # train model \n",
    "        model, history = train_model(scaled_train_data, \n",
    "                latent_dim, n_layer1_in_20s, n_layer2_in_25s, n_layer3_in_50s,\n",
    "                epochs = 100)\n",
    "\n",
    "        # evaluate on valid data\n",
    "        score = evaluate_model(model, scaled_valid_data)\n",
    "        \n",
    "        # Get the loss after the last training-epoch.        \n",
    "        losses.append(score['loss'])\n",
    "    \n",
    "    loss = np.mean(losses)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "\n",
    "    # Print the loss.\n",
    "    print(f\"trial vae loss: {loss}\")\n",
    "    print(f\"best vae loss: {best_loss}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"Trial run time: {np.round((end - start)/60.0, 2)} minutes\") \n",
    "    print('-------------------------------------------')   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Time VAE HPO Loop, by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "trial_num: 1\n",
      "latent_dim: 8\n",
      "n_layer1_in_20s: 2\n",
      "n_layer2_in_25s: 4\n",
      "n_layer3_in_50s: 4\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 429.33123779296875\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 2\n",
      "latent_dim: 7\n",
      "n_layer1_in_20s: 4\n",
      "n_layer2_in_25s: 7\n",
      "n_layer3_in_50s: 7\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 450.917431640625\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 3\n",
      "latent_dim: 5\n",
      "n_layer1_in_20s: 2\n",
      "n_layer2_in_25s: 1\n",
      "n_layer3_in_50s: 3\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 522.7973876953125\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 4\n",
      "latent_dim: 8\n",
      "n_layer1_in_20s: 3\n",
      "n_layer2_in_25s: 4\n",
      "n_layer3_in_50s: 7\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 435.1085571289062\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 5\n",
      "latent_dim: 7\n",
      "n_layer1_in_20s: 2\n",
      "n_layer2_in_25s: 8\n",
      "n_layer3_in_50s: 2\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 457.21519775390624\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 6\n",
      "latent_dim: 6\n",
      "n_layer1_in_20s: 4\n",
      "n_layer2_in_25s: 5\n",
      "n_layer3_in_50s: 6\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 477.5411743164062\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 7\n",
      "latent_dim: 8\n",
      "n_layer1_in_20s: 2\n",
      "n_layer2_in_25s: 4\n",
      "n_layer3_in_50s: 4\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 438.81138916015624\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 8\n",
      "latent_dim: 8\n",
      "n_layer1_in_20s: 1\n",
      "n_layer2_in_25s: 3\n",
      "n_layer3_in_50s: 3\n",
      "scaling_method: minmax\n",
      "\n",
      "trial vae loss: 440.20277099609376\n",
      "best vae loss: 429.33123779296875\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "trial_num: 9\n",
      "latent_dim: 4\n",
      "n_layer1_in_20s: 1\n",
      "n_layer2_in_25s: 6\n",
      "n_layer3_in_50s: 5\n",
      "scaling_method: minmax\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a5a88115703e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# the number of subsequent evaluations of f(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         )\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/skopt/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# Call the wrapped objective function with the named arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mobjective_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marg_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobjective_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-54209af8fd0f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(latent_dim, n_layer1_in_20s, n_layer2_in_25s, n_layer3_in_50s, scaling_method)\u001b[0m\n\u001b[1;32m     37\u001b[0m         model, history = train_model(scaled_train_data, \n\u001b[1;32m     38\u001b[0m                 \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layer1_in_20s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layer2_in_25s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layer3_in_50s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 epochs = 100)\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# evaluate on valid data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-e1285a9c58ea>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_data, latent_dim, n_layer1_in_20s, n_layer2_in_25s, n_layer3_in_50s, epochs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduceLR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# how many folds in cross validation\n",
    "num_folds = 5\n",
    "\n",
    "# num of trials for Bayesian search: initial and total (including initial)\n",
    "n_initial_points = 5\n",
    "n_calls = 60\n",
    "\n",
    "\n",
    "# our model name\n",
    "model = 'vae_conv_I'\n",
    "\n",
    "# dataset_names = ['sine', 'stocks', 'air', 'energy']\n",
    "percs = [2, 5, 10, 20, 100]\n",
    "\n",
    "\n",
    "# to custom run specific data\n",
    "dataset_names = ['sine']\n",
    "percs = [ 20 ]\n",
    "\n",
    "\n",
    "# set random gen seed for reproducibiity\n",
    "set_seeds(42)\n",
    "\n",
    "main_start_time = time.time()    \n",
    "\n",
    "for data_name in dataset_names:    \n",
    "    for p in percs:  \n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        ### file name to load\n",
    "        fname = f'{input_dir + data_name}_subsampled_train_perc_{p}.npz'\n",
    "        \n",
    "        ### read data        \n",
    "        loaded = np.load(fname)\n",
    "        data = loaded['data']  \n",
    "        # print(fname, data.shape) \n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        \n",
    "        # k-folds \n",
    "        kf = KFold(n_splits=num_folds)\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        best_loss = 1e10\n",
    "        trial_num = 1\n",
    "        \n",
    "        # bayesian search\n",
    "        gp_ = gp_minimize(\n",
    "            objective, # the objective function to minimize\n",
    "            param_grid, # the hyperparameter space\n",
    "            x0=default_parameters, # the initial parameters to test\n",
    "            acq_func='EI', # the acquisition function\n",
    "            n_initial_points=n_initial_points,\n",
    "            n_calls=n_calls, # the number of subsequent evaluations of f(x)\n",
    "            random_state=0, \n",
    "            n_jobs=7\n",
    "        )\n",
    "               \n",
    "        \n",
    "\n",
    "end = time.time()\n",
    "elapsed_time = np.round((end - main_start_time)/60.0, 2)\n",
    "print(f\"All done in {elapsed_time} minutes!\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
