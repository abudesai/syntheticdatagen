{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/site-packages (from scipy) (1.18.5)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import joblib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sys \n",
    "import time\n",
    "\n",
    "# from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.discriminative_metrics2 import discriminative_score_metrics\n",
    "\n",
    "# from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.predictive_metrics2 import predictive_score_metrics\n",
    "\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_dir = \"../data/processed_orig_data/\"\n",
    "gen_data_dir = \"../data/generated_data/\"\n",
    "\n",
    "scores_dir = './scores/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler():\n",
    "    \"\"\"Min Max normalizer.\n",
    "    Args:\n",
    "    - data: original data\n",
    "\n",
    "    Returns:\n",
    "    - norm_data: normalized data\n",
    "    \"\"\"\n",
    "    def fit_transform(self, data): \n",
    "        self.fit(data)\n",
    "        scaled_data = self.transform(data)\n",
    "        return scaled_data\n",
    "\n",
    "\n",
    "    def fit(self, data):    \n",
    "        self.mini = np.min(data, 0)\n",
    "        self.range = np.max(data, 0) - self.mini\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self, data):\n",
    "        numerator = data - self.mini\n",
    "        scaled_data = numerator / (self.range + 1e-7)\n",
    "        return scaled_data\n",
    "\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        data *= self.range\n",
    "        data += self.mini\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "Data: stocks; Training Size: 2\n",
      "ori_data shape:  (49, 24, 6) gen_data shape:  (49, 24, 6)\n",
      "------------------------------------------------------------------------------------------\n",
      "Discrimination Score :\n",
      "Avg. train / val loss for epoch 0: 0.642 / 0.525 \n",
      "Avg. train / val loss for epoch 50: 0.438 / 0.372 \n",
      "Avg. train / val loss for epoch 100: 0.276 / 0.201 \n",
      "Avg. train / val loss for epoch 150: 0.192 / 0.089 \n",
      "Avg. train / val loss for epoch 200: 0.172 / 0.064 \n",
      "Avg. train / val loss for epoch 250: 0.105 / 0.171 \n",
      "Avg. train / val loss for epoch 300: 0.104 / 0.059 \n",
      "Avg. train / val loss for epoch 350: 0.102 / 0.032 \n",
      "Avg. train / val loss for epoch 400: 0.087 / 0.03 \n",
      "Avg. train / val loss for epoch 450: 0.083 / 0.027 \n",
      "----------  disc iter:  0 score:  0.5 ----------\n",
      "Avg. train / val loss for epoch 0: 0.491 / 0.448 \n",
      "Avg. train / val loss for epoch 50: 0.308 / 0.224 \n",
      "Avg. train / val loss for epoch 100: 0.223 / 0.15 \n",
      "Avg. train / val loss for epoch 150: 0.169 / 0.106 \n",
      "Avg. train / val loss for epoch 200: 0.15 / 0.082 \n",
      "Avg. train / val loss for epoch 250: 0.139 / 0.069 \n",
      "Avg. train / val loss for epoch 300: 0.131 / 0.061 \n",
      "Avg. train / val loss for epoch 350: 0.124 / 0.056 \n",
      "Avg. train / val loss for epoch 400: 0.114 / 0.049 \n",
      "Avg. train / val loss for epoch 450: 0.103 / 0.047 \n",
      "----------  disc iter:  1 score:  0.44999999999999996 ----------\n",
      "Avg. train / val loss for epoch 0: 0.696 / 0.653 \n",
      "Avg. train / val loss for epoch 50: 0.479 / 0.477 \n",
      "Avg. train / val loss for epoch 100: 0.264 / 0.374 \n",
      "Avg. train / val loss for epoch 150: 0.155 / 0.379 \n",
      "Avg. train / val loss for epoch 200: 0.111 / 0.399 \n",
      "Avg. train / val loss for epoch 250: 0.07 / 0.422 \n",
      "Avg. train / val loss for epoch 300: 0.049 / 0.439 \n",
      "Avg. train / val loss for epoch 350: 0.037 / 0.458 \n",
      "Avg. train / val loss for epoch 400: 0.029 / 0.476 \n",
      "Avg. train / val loss for epoch 450: 0.024 / 0.494 \n",
      "----------  disc iter:  2 score:  0.44999999999999996 ----------\n",
      "Avg. train / val loss for epoch 0: 1.054 / 1.008 \n",
      "Avg. train / val loss for epoch 50: 0.649 / 0.461 \n",
      "Avg. train / val loss for epoch 100: 0.44 / 0.279 \n",
      "Avg. train / val loss for epoch 150: 0.304 / 0.192 \n",
      "Avg. train / val loss for epoch 200: 0.199 / 0.115 \n",
      "Avg. train / val loss for epoch 250: 0.145 / 0.061 \n",
      "Avg. train / val loss for epoch 300: 0.137 / 0.062 \n",
      "Avg. train / val loss for epoch 350: 0.124 / 0.048 \n",
      "Avg. train / val loss for epoch 400: 0.115 / 0.045 \n",
      "Avg. train / val loss for epoch 450: 0.1 / 0.036 \n",
      "----------  disc iter:  3 score:  0.44999999999999996 ----------\n",
      "Avg. train / val loss for epoch 0: 0.698 / 0.646 \n",
      "Avg. train / val loss for epoch 50: 0.465 / 0.489 \n",
      "Avg. train / val loss for epoch 100: 0.255 / 0.407 \n",
      "Avg. train / val loss for epoch 150: 0.14 / 0.379 \n",
      "Avg. train / val loss for epoch 200: 0.108 / 0.396 \n",
      "Avg. train / val loss for epoch 250: 0.094 / 0.413 \n",
      "Avg. train / val loss for epoch 300: 0.086 / 0.431 \n",
      "Avg. train / val loss for epoch 350: 0.081 / 0.446 \n",
      "Avg. train / val loss for epoch 400: 0.078 / 0.456 \n",
      "Avg. train / val loss for epoch 450: 0.076 / 0.465 \n",
      "----------  disc iter:  4 score:  0.44999999999999996 ----------\n",
      "------------------------------------------------------------------------------------------\n",
      "Discrimination Score :\n",
      "Discriminative score: 0.46\n",
      "Discriminative score CI:  0.0278\n",
      "------------------------------------------------------------------------------------------\n",
      "Predictive Score :\n",
      "Avg. train / val loss for epoch 0: 0.723 / 0.496 \n",
      "Avg. train / val loss for epoch 50: 0.398 / 0.457 \n",
      "Avg. train / val loss for epoch 100: 0.29 / 0.383 \n",
      "Avg. train / val loss for epoch 150: 0.218 / 0.289 \n",
      "Avg. train / val loss for epoch 200: 0.184 / 0.223 \n",
      "Avg. train / val loss for epoch 250: 0.166 / 0.193 \n",
      "Avg. train / val loss for epoch 300: 0.154 / 0.18 \n",
      "Avg. train / val loss for epoch 350: 0.144 / 0.174 \n",
      "Avg. train / val loss for epoch 400: 0.135 / 0.17 \n",
      "Avg. train / val loss for epoch 450: 0.127 / 0.171 \n",
      "----------  pred iter:  0 score:  0.17557572 ----------\n",
      "Avg. train / val loss for epoch 0: 0.47 / 0.452 \n",
      "Avg. train / val loss for epoch 50: 0.331 / 0.295 \n",
      "Avg. train / val loss for epoch 100: 0.259 / 0.201 \n",
      "Avg. train / val loss for epoch 150: 0.195 / 0.14 \n",
      "Avg. train / val loss for epoch 200: 0.167 / 0.12 \n",
      "Avg. train / val loss for epoch 250: 0.154 / 0.126 \n",
      "Avg. train / val loss for epoch 300: 0.146 / 0.122 \n",
      "Avg. train / val loss for epoch 350: 0.14 / 0.135 \n",
      "Avg. train / val loss for epoch 400: 0.134 / 0.137 \n",
      "Avg. train / val loss for epoch 450: 0.129 / 0.142 \n",
      "----------  pred iter:  1 score:  0.15093242 ----------\n",
      "Avg. train / val loss for epoch 0: 0.284 / 0.331 \n",
      "Avg. train / val loss for epoch 50: 0.214 / 0.259 \n",
      "Avg. train / val loss for epoch 100: 0.166 / 0.194 \n",
      "Avg. train / val loss for epoch 150: 0.144 / 0.179 \n",
      "Avg. train / val loss for epoch 200: 0.134 / 0.159 \n",
      "Avg. train / val loss for epoch 250: 0.128 / 0.156 \n",
      "Avg. train / val loss for epoch 300: 0.123 / 0.146 \n",
      "Avg. train / val loss for epoch 350: 0.12 / 0.147 \n",
      "Avg. train / val loss for epoch 400: 0.117 / 0.148 \n",
      "Avg. train / val loss for epoch 450: 0.114 / 0.141 \n",
      "----------  pred iter:  2 score:  0.13509901 ----------\n",
      "Avg. train / val loss for epoch 0: 0.331 / 0.312 \n",
      "Avg. train / val loss for epoch 50: 0.223 / 0.212 \n",
      "Avg. train / val loss for epoch 100: 0.182 / 0.177 \n",
      "Avg. train / val loss for epoch 150: 0.164 / 0.155 \n",
      "Avg. train / val loss for epoch 200: 0.153 / 0.141 \n",
      "Avg. train / val loss for epoch 250: 0.145 / 0.13 \n",
      "Avg. train / val loss for epoch 300: 0.138 / 0.117 \n",
      "Avg. train / val loss for epoch 350: 0.131 / 0.106 \n",
      "Avg. train / val loss for epoch 400: 0.124 / 0.096 \n",
      "Avg. train / val loss for epoch 450: 0.12 / 0.092 \n",
      "----------  pred iter:  3 score:  0.146775 ----------\n",
      "Avg. train / val loss for epoch 0: 0.314 / 0.257 \n",
      "Avg. train / val loss for epoch 50: 0.19 / 0.18 \n",
      "Avg. train / val loss for epoch 100: 0.165 / 0.148 \n",
      "Avg. train / val loss for epoch 150: 0.153 / 0.13 \n",
      "Avg. train / val loss for epoch 200: 0.146 / 0.121 \n",
      "Avg. train / val loss for epoch 250: 0.142 / 0.121 \n",
      "Avg. train / val loss for epoch 300: 0.138 / 0.117 \n",
      "Avg. train / val loss for epoch 350: 0.136 / 0.116 \n",
      "Avg. train / val loss for epoch 400: 0.134 / 0.112 \n",
      "Avg. train / val loss for epoch 450: 0.132 / 0.109 \n",
      "----------  pred iter:  4 score:  0.17384708 ----------\n",
      "Predictive score: 0.1564\n",
      "Predictive score CI:  0.0219\n",
      "\n",
      "\n",
      "Total run time: 13.29 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "metric_iteration = 5\n",
    "\n",
    "# model name\n",
    "model = 'vae_conv_I'      # vae_conv_I, vae_IN, tforcing\n",
    "\n",
    "disc_epochs = 500 ; pred_epochs = 500\n",
    "\n",
    "# full selection of data to run\n",
    "training_sizes = [2, 5, 10, 20, 100]\n",
    "datasets = ['sine', 'stocks', 'energy', 'air']\n",
    "\n",
    "\n",
    "# custom selection \n",
    "training_sizes = [ 2 ]\n",
    "datasets = ['stocks']\n",
    "\n",
    "data = []\n",
    "for dataset in datasets:\n",
    "\n",
    "    for training_size in training_sizes:\n",
    "\n",
    "        print('-'*90); print('-'*90)\n",
    "        print(f\"Data: {dataset}; Training Size: {training_size}\")\n",
    "\n",
    "        ## original data \n",
    "        fname = f'{orig_data_dir + dataset}_subsampled_train_perc_{training_size}.npz'\n",
    "        loaded = np.load(fname)\n",
    "        ori_data = loaded['data']\n",
    "\n",
    "        # generated data \n",
    "        sample_file_name = gen_data_dir + f'{model}/{model}_gen_samples_{dataset}_perc_{training_size}.npz'\n",
    "        loaded = np.load(sample_file_name)\n",
    "        gen_data = loaded['data']   \n",
    "\n",
    "#         sample_file_name = gen_data_dir + f'{model}/{model}_gen_samples_{dataset}_{training_size}'\n",
    "#         gen_data = joblib.load(sample_file_name)\n",
    "#         gen_data = gen_data[0:ori_data.shape[0]]\n",
    "        \n",
    "        \n",
    "        ## scale orig and generated data\n",
    "        scaler_orig = MinMaxScaler( )  \n",
    "        scaled_ori_data = scaler_orig.fit_transform(ori_data)\n",
    "        scaled_gen_data = scaler_orig.transform(gen_data)         \n",
    "        print('ori_data shape: ', ori_data.shape, 'gen_data shape: ', gen_data.shape)\n",
    "        \n",
    "    #     ---------------------------------------------------------------------------\n",
    "#         print(\"-\"*90); print('Visualizations:')\n",
    "        # visualization(scaled_ori_data[0:scaled_gen_data.shape[0]], scaled_gen_data, 'pca')\n",
    "#         visualization(scaled_ori_data[0:scaled_gen_data.shape[0]], scaled_gen_data, 'tsne')\n",
    "\n",
    "#            ---------------------------------------------------------------------------\n",
    "        print(\"-\"*90); print('Discrimination Score :')\n",
    "        discriminative_score = list()\n",
    "        for tt in range(metric_iteration):\n",
    "            temp_disc = discriminative_score_metrics(scaled_ori_data, scaled_gen_data,  epochs = disc_epochs)\n",
    "            discriminative_score.append(temp_disc)  \n",
    "            print(\"----------  disc iter: \", tt, 'score: ', temp_disc, '----------')\n",
    "\n",
    "        disc_mean = np.round(np.mean(discriminative_score), 4)\n",
    "        disc_CI = np.round(confidence_interval(discriminative_score)[1], 4)\n",
    "        print(\"-\"*90); print('Discrimination Score :')\n",
    "        print('Discriminative score: ' + str(disc_mean))\n",
    "        print(\"Discriminative score CI: \", disc_CI)\n",
    "        #     ---------------------------------------------------------------------------             \n",
    "        print(\"-\"*90); print('Predictive Score :')\n",
    "        predictive_score = list()\n",
    "        for tt in range(metric_iteration):\n",
    "            temp_pred = predictive_score_metrics(scaled_ori_data, scaled_gen_data, epochs = pred_epochs)\n",
    "            predictive_score.append(temp_pred)   \n",
    "            print(\"----------  pred iter: \", tt, 'score: ', temp_pred, '----------')\n",
    "        \n",
    "        pred_mean = np.round(np.mean(predictive_score), 4)\n",
    "        pred_CI = np.round(confidence_interval(predictive_score)[1], 4)\n",
    "        print('Predictive score: ' + str(pred_mean))\n",
    "        print(\"Predictive score CI: \", pred_CI)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        #     ---------------------------------------------------------------------------\n",
    "        # save results\n",
    "        data =  [[  model,  dataset,   training_size,   metric_iteration,  \n",
    "                      disc_epochs, disc_mean,  disc_CI,  \n",
    "                      pred_epochs, pred_mean,  pred_CI  ]]\n",
    "        cols = ['model', 'dataset', 'train_perc', 'iters', \n",
    "                    'disc_epochs' , 'disc_mean', 'disc_CI', \n",
    "                    'pred_epochs', 'pred_mean', 'pred_CI']\n",
    "        df = pd.DataFrame(data, columns = cols)\n",
    "        df.to_csv(f\"./{scores_dir}/{model}_disc_and_pred_scores_{dataset}_{training_size}.csv\", index=False, float_format='%.4f')\n",
    "end = time.time()\n",
    "print(f\"Total run time: {np.round((end - start)/60.0, 2)} minutes\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all score files into single file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "././scores//vae_conv_I_disc_and_pred_scores_sine_2.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_sine_5.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_sine_10.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_sine_20.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_sine_100.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks_2.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks_5.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks_10.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks_20.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks_100.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks2_2.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks2_5.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks2_10.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks2_20.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_stocks2_100.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_energy_2.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_energy_5.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_energy_10.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_energy_20.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_energy_100.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_air_2.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_air_5.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_air_10.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_air_20.csv\n",
      "././scores//vae_conv_I_disc_and_pred_scores_air_100.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_perc</th>\n",
       "      <th>iters</th>\n",
       "      <th>disc_epochs</th>\n",
       "      <th>disc_mean</th>\n",
       "      <th>disc_CI</th>\n",
       "      <th>pred_epochs</th>\n",
       "      <th>pred_mean</th>\n",
       "      <th>pred_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.039</td>\n",
       "      <td>500</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.025</td>\n",
       "      <td>500</td>\n",
       "      <td>0.218</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.037</td>\n",
       "      <td>500</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.030</td>\n",
       "      <td>500</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.089</td>\n",
       "      <td>500</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model dataset  train_perc  iters  disc_epochs  disc_mean  disc_CI  \\\n",
       "0  vae_conv_I    sine           2      5          500      0.472    0.039   \n",
       "1  vae_conv_I    sine           5      5          500      0.041    0.025   \n",
       "2  vae_conv_I    sine          10      5          500      0.089    0.037   \n",
       "3  vae_conv_I    sine          20      5          500      0.112    0.030   \n",
       "4  vae_conv_I    sine         100      5          500      0.228    0.089   \n",
       "\n",
       "   pred_epochs  pred_mean  pred_CI  \n",
       "0          500      0.280    0.034  \n",
       "1          500      0.218    0.000  \n",
       "2          500      0.215    0.001  \n",
       "3          500      0.216    0.000  \n",
       "4          500      0.214    0.000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'vae_conv_I'\n",
    "\n",
    "training_sizes = [2, 5, 10, 20, 100]\n",
    "\n",
    "datasets = ['sine', 'stocks', 'stocks2', 'energy', 'air']\n",
    "\n",
    "all_scores = []\n",
    "for dataset in datasets:\n",
    "    for training_size in training_sizes:\n",
    "        fname = f\"./{scores_dir}/{model}_disc_and_pred_scores_{dataset}_{training_size}.csv\"\n",
    "        if os.path.exists(fname):\n",
    "            print(fname)\n",
    "            data = pd.read_csv(fname)\n",
    "            all_scores.append(data)\n",
    "all_scores = pd.concat(all_scores, ignore_index=True)\n",
    "all_scores = all_scores.round(3)\n",
    "all_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.to_csv(f\"./{scores_dir}/{model}_disc_and_pred_scores_ALL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nicely organized score table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_perc</th>\n",
       "      <th>disc_mean</th>\n",
       "      <th>disc_CI</th>\n",
       "      <th>pred_mean</th>\n",
       "      <th>pred_CI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>2</td>\n",
       "      <td>.472</td>\n",
       "      <td>.039</td>\n",
       "      <td>.280</td>\n",
       "      <td>.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>5</td>\n",
       "      <td>.041</td>\n",
       "      <td>.025</td>\n",
       "      <td>.218</td>\n",
       "      <td>.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>10</td>\n",
       "      <td>.089</td>\n",
       "      <td>.037</td>\n",
       "      <td>.215</td>\n",
       "      <td>.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>20</td>\n",
       "      <td>.112</td>\n",
       "      <td>.030</td>\n",
       "      <td>.216</td>\n",
       "      <td>.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>100</td>\n",
       "      <td>.228</td>\n",
       "      <td>.089</td>\n",
       "      <td>.214</td>\n",
       "      <td>.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model dataset  train_perc disc_mean disc_CI pred_mean pred_CI\n",
       "0  vae_conv_I    sine           2      .472    .039      .280    .034\n",
       "1  vae_conv_I    sine           5      .041    .025      .218    .000\n",
       "2  vae_conv_I    sine          10      .089    .037      .215    .001\n",
       "3  vae_conv_I    sine          20      .112    .030      .216    .000\n",
       "4  vae_conv_I    sine         100      .228    .089      .214    .000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = all_scores[['model', 'dataset', 'train_perc', 'disc_mean', 'disc_CI', \n",
    "                        'pred_mean', 'pred_CI']]\n",
    "\n",
    "new_df['disc_mean'] = new_df['disc_mean'].apply(lambda x: f'{x:0.3f}'[1:] )\n",
    "new_df['disc_CI'] = new_df['disc_CI'].apply(lambda x: f'{x:0.3f}'[1:] )\n",
    "new_df['pred_mean'] = new_df['pred_mean'].apply(lambda x: f'{x:0.3f}'[1:] )\n",
    "new_df['pred_CI'] = new_df['pred_CI'].apply(lambda x: f'{x:0.3f}'[1:] )\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>train_perc</th>\n",
       "      <th>disc_score</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>2</td>\n",
       "      <td>.472 +/- .039</td>\n",
       "      <td>.280 +/- .034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>5</td>\n",
       "      <td>.041 +/- .025</td>\n",
       "      <td>.218 +/- .000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>10</td>\n",
       "      <td>.089 +/- .037</td>\n",
       "      <td>.215 +/- .001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>20</td>\n",
       "      <td>.112 +/- .030</td>\n",
       "      <td>.216 +/- .000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>sine</td>\n",
       "      <td>100</td>\n",
       "      <td>.228 +/- .089</td>\n",
       "      <td>.214 +/- .000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model dataset  train_perc     disc_score     pred_score\n",
       "0  vae_conv_I    sine           2  .472 +/- .039  .280 +/- .034\n",
       "1  vae_conv_I    sine           5  .041 +/- .025  .218 +/- .000\n",
       "2  vae_conv_I    sine          10  .089 +/- .037  .215 +/- .001\n",
       "3  vae_conv_I    sine          20  .112 +/- .030  .216 +/- .000\n",
       "4  vae_conv_I    sine         100  .228 +/- .089  .214 +/- .000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['disc_score'] = new_df.apply( lambda row:row['disc_mean'] + ' +/- ' + row['disc_CI'], axis = 1 )\n",
    "new_df['pred_score'] = new_df.apply( lambda row: row['pred_mean'] + ' +/- ' + row['pred_CI'], axis = 1 )\n",
    "\n",
    "new_df.drop(columns=['disc_mean', 'disc_CI','pred_mean', 'pred_CI'], inplace=True) \n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>metric</th>\n",
       "      <th>model</th>\n",
       "      <th>train_perc</th>\n",
       "      <th>air</th>\n",
       "      <th>energy</th>\n",
       "      <th>sine</th>\n",
       "      <th>stocks</th>\n",
       "      <th>stocks2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disc_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>2</td>\n",
       "      <td>.497 +/- .008</td>\n",
       "      <td>.485 +/- .015</td>\n",
       "      <td>.472 +/- .039</td>\n",
       "      <td>.450 +/- .000</td>\n",
       "      <td>.482 +/- .031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disc_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>5</td>\n",
       "      <td>.401 +/- .271</td>\n",
       "      <td>.498 +/- .003</td>\n",
       "      <td>.041 +/- .025</td>\n",
       "      <td>.403 +/- .025</td>\n",
       "      <td>.460 +/- .055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disc_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>10</td>\n",
       "      <td>.498 +/- .003</td>\n",
       "      <td>.500 +/- .000</td>\n",
       "      <td>.089 +/- .037</td>\n",
       "      <td>.422 +/- .124</td>\n",
       "      <td>.297 +/- .215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disc_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>20</td>\n",
       "      <td>.500 +/- .000</td>\n",
       "      <td>.500 +/- .000</td>\n",
       "      <td>.112 +/- .030</td>\n",
       "      <td>.496 +/- .005</td>\n",
       "      <td>.431 +/- .126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>disc_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>100</td>\n",
       "      <td>.499 +/- .000</td>\n",
       "      <td>.500 +/- .000</td>\n",
       "      <td>.228 +/- .089</td>\n",
       "      <td>.374 +/- .054</td>\n",
       "      <td>.396 +/- .065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pred_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>2</td>\n",
       "      <td>.069 +/- .005</td>\n",
       "      <td>.266 +/- .003</td>\n",
       "      <td>.280 +/- .034</td>\n",
       "      <td>.193 +/- .103</td>\n",
       "      <td>.163 +/- .016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pred_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>5</td>\n",
       "      <td>.046 +/- .002</td>\n",
       "      <td>.295 +/- .003</td>\n",
       "      <td>.218 +/- .000</td>\n",
       "      <td>.128 +/- .005</td>\n",
       "      <td>.122 +/- .019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pred_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>10</td>\n",
       "      <td>.005 +/- .000</td>\n",
       "      <td>.292 +/- .002</td>\n",
       "      <td>.215 +/- .001</td>\n",
       "      <td>.103 +/- .004</td>\n",
       "      <td>.074 +/- .000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pred_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>20</td>\n",
       "      <td>.011 +/- .001</td>\n",
       "      <td>.319 +/- .002</td>\n",
       "      <td>.216 +/- .000</td>\n",
       "      <td>.104 +/- .001</td>\n",
       "      <td>.051 +/- .001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pred_score</td>\n",
       "      <td>vae_conv_I</td>\n",
       "      <td>100</td>\n",
       "      <td>.008 +/- .001</td>\n",
       "      <td>.342 +/- .014</td>\n",
       "      <td>.214 +/- .000</td>\n",
       "      <td>.040 +/- .000</td>\n",
       "      <td>.018 +/- .000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset      metric       model  train_perc            air         energy  \\\n",
       "0        disc_score  vae_conv_I           2  .497 +/- .008  .485 +/- .015   \n",
       "1        disc_score  vae_conv_I           5  .401 +/- .271  .498 +/- .003   \n",
       "2        disc_score  vae_conv_I          10  .498 +/- .003  .500 +/- .000   \n",
       "3        disc_score  vae_conv_I          20  .500 +/- .000  .500 +/- .000   \n",
       "4        disc_score  vae_conv_I         100  .499 +/- .000  .500 +/- .000   \n",
       "5        pred_score  vae_conv_I           2  .069 +/- .005  .266 +/- .003   \n",
       "6        pred_score  vae_conv_I           5  .046 +/- .002  .295 +/- .003   \n",
       "7        pred_score  vae_conv_I          10  .005 +/- .000  .292 +/- .002   \n",
       "8        pred_score  vae_conv_I          20  .011 +/- .001  .319 +/- .002   \n",
       "9        pred_score  vae_conv_I         100  .008 +/- .001  .342 +/- .014   \n",
       "\n",
       "dataset           sine         stocks        stocks2  \n",
       "0        .472 +/- .039  .450 +/- .000  .482 +/- .031  \n",
       "1        .041 +/- .025  .403 +/- .025  .460 +/- .055  \n",
       "2        .089 +/- .037  .422 +/- .124  .297 +/- .215  \n",
       "3        .112 +/- .030  .496 +/- .005  .431 +/- .126  \n",
       "4        .228 +/- .089  .374 +/- .054  .396 +/- .065  \n",
       "5        .280 +/- .034  .193 +/- .103  .163 +/- .016  \n",
       "6        .218 +/- .000  .128 +/- .005  .122 +/- .019  \n",
       "7        .215 +/- .001  .103 +/- .004  .074 +/- .000  \n",
       "8        .216 +/- .000  .104 +/- .001  .051 +/- .001  \n",
       "9        .214 +/- .000  .040 +/- .000  .018 +/- .000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "non_pivoted_columns = ['model', 'train_perc']\n",
    "pivoting_column = ['dataset']\n",
    "metrics = ['disc_score', 'pred_score']\n",
    "\n",
    "final_df = []\n",
    "for metric in metrics: \n",
    "    pivoted_columns = metric\n",
    "    cols = non_pivoted_columns + pivoting_column + [pivoted_columns]\n",
    "    temp_df = new_df[cols]\n",
    "    \n",
    "\n",
    "    pivoted = temp_df.pivot_table(index = non_pivoted_columns, \n",
    "                                          aggfunc=lambda x: ' '.join(x),\n",
    "                                          columns=pivoting_column, \n",
    "                                          values=pivoted_columns).reset_index()\n",
    "    pivoted.insert(0, 'metric', metric)    \n",
    "    \n",
    "    final_df.append(pivoted)\n",
    "\n",
    "\n",
    "final_df = pd.concat(final_df, axis=0, ignore_index=True)\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(f\"./{scores_dir}/{model}_disc_and_pred_scores_ALL_PIVOTED.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
