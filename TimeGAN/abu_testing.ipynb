{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (8.2.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/site-packages (from scipy) (1.18.5)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sys \n",
    "\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_dir = './data/orig/'\n",
    "gen_data_dir = './data/generated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'energy'      # sine, stocks, energy, air"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler():\n",
    "    \"\"\"Min Max normalizer.\n",
    "    Args:\n",
    "    - data: original data\n",
    "\n",
    "    Returns:\n",
    "    - norm_data: normalized data\n",
    "    \"\"\"\n",
    "    def fit(self, data):    \n",
    "        self.mini = np.min(data, 0)\n",
    "        numerator = data - self.mini\n",
    "        self.range = np.max(data, 0) - self.mini\n",
    "        norm_data = numerator / (self.range + 1e-7)\n",
    "        return norm_data\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        data *= self.range\n",
    "        data += self.mini\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom scaler for 3d data\n",
    "class MinMaxScaler_Feat_Dim():\n",
    "    '''Scales history and forecast parts of time-series based on history data'''\n",
    "    def __init__(self, scaling_len, input_dim, upper_bound = 3., lower_bound = -3.):         \n",
    "        self.scaling_len = scaling_len\n",
    "        self.min_vals_per_d = None      \n",
    "        self.max_vals_per_d = None  \n",
    "        self.input_dim = input_dim\n",
    "        self.upper_bound = upper_bound\n",
    "        self.lower_bound = lower_bound\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None): \n",
    "\n",
    "        if self.scaling_len < 1: \n",
    "            msg = f''' Error scaling series. \n",
    "            scaling_len needs to be at least 2. Given length is {self.scaling_len}.  '''\n",
    "            raise Exception(msg)\n",
    "\n",
    "        X_f = X[ :,  : self.scaling_len , : ]\n",
    "        self.min_vals_per_d = np.expand_dims(np.expand_dims(X_f.min(axis=0).min(axis=0), axis=0), axis=0)\n",
    "        self.max_vals_per_d = np.expand_dims(np.expand_dims(X_f.max(axis=0).max(axis=0), axis=0), axis=0)\n",
    "\n",
    "        self.range_per_d = self.max_vals_per_d - self.min_vals_per_d\n",
    "        self.range_per_d = np.where(self.range_per_d == 0, 1e-5, self.range_per_d)\n",
    "\n",
    "        # print(self.min_vals_per_d.shape); print(self.max_vals_per_d.shape)\n",
    "              \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None): \n",
    "        assert X.shape[-1] == self.min_vals_per_d.shape[-1], \"Error: Dimension of array to scale doesn't match fitted array.\"\n",
    "         \n",
    "        X = X - self.min_vals_per_d\n",
    "        X = np.divide(X, self.range_per_d )        \n",
    "        X = np.where( X < self.upper_bound, X, self.upper_bound)\n",
    "        X = np.where( X > self.lower_bound, X, self.lower_bound)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "        \n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        X = X.copy()\n",
    "        X = X * self.range_per_d \n",
    "        X = X + self.min_vals_per_d\n",
    "        # print(X.shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "Data: sine; Training Size: 2\n",
      "orig data shape:  (200, 24, 5)\n",
      "------------------------------------------------------------------------------------------\n",
      "Predictive Score :\n",
      "itt: 500 ploss: 0.31419238\n",
      "itt: 1000 ploss: 0.30140588\n",
      "itt: 1500 ploss: 0.31075373\n",
      "itt: 2000 ploss: 0.30696774\n",
      "itt: 2500 ploss: 0.31377903\n",
      "itt: 3000 ploss: 0.31716377\n",
      "itt: 3500 ploss: 0.30621698\n",
      "Final p_loss 0.3080899 predictive_score: 0.30808991724221463\n",
      "Predictive score: 0.3081\n",
      "Predictive score CI:  nan\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------------------------\n",
      "Data: sine; Training Size: 5\n",
      "orig data shape:  (500, 24, 5)\n",
      "------------------------------------------------------------------------------------------\n",
      "Predictive Score :\n",
      "itt: 500 ploss: 0.3128918\n",
      "itt: 1000 ploss: 0.3260546\n",
      "itt: 1500 ploss: 0.31478286\n",
      "itt: 2000 ploss: 0.32348353\n",
      "itt: 2500 ploss: 0.3181019\n",
      "itt: 3000 ploss: 0.3156176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metric_iteration = 1\n",
    "\n",
    "training_sizes = [2, 5, 10, 20, 100]\n",
    "datasets = ['sine', 'stocks', 'energy']\n",
    "\n",
    "training_sizes = [2, 5, 10]\n",
    "datasets = ['sine']\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    for training_size in training_sizes:\n",
    "\n",
    "        print('-'*90); print('-'*90)\n",
    "        print(f\"Data: {dataset}; Training Size: {training_size}\")\n",
    "\n",
    "    #     original data\n",
    "        fname = f'{orig_data_dir + dataset}_subsampled_train_perc_{training_size}.npz'\n",
    "        loaded = np.load(fname)\n",
    "        ori_data = loaded['data']\n",
    "\n",
    "        scaler_orig = MinMaxScaler( )  \n",
    "        ori_data = scaler_orig.fit(ori_data)\n",
    "        print('orig data shape: ', ori_data.shape)\n",
    "\n",
    "    #     generated data\n",
    "        #loaded = np.load(\"new_Time_vae_files/vae_conv_I_gen_samples_sine_perc_\"+str(training_size)+\".npz\")        \n",
    "        #generated_data = MinMaxScaler(loaded[\"data\"])\n",
    "\n",
    "\n",
    "        sample_file_name = gen_data_dir + f'vae_conv_I_gen_samples_{dataset}_perc_{training_size}.npz'\n",
    "        loaded = np.load(sample_file_name)\n",
    "        generated_data = loaded['data']\n",
    "\n",
    "        # Abu scaler \n",
    "    #     gen_scaler = MinMaxScaler_Feat_Dim( scaling_len = T, input_dim = D, upper_bound = 3.0, lower_bound = -3.0 )  \n",
    "    #     generated_data = gen_scaler.fit_transform(generated_data)\n",
    "\n",
    "        gen_scaler = MinMaxScaler()  \n",
    "        generated_data = gen_scaler.fit(generated_data)    \n",
    "    #     print('generated_data shape:', generated_data.shape)\n",
    "\n",
    "    #     print('means: ', ori_data.mean(axis=(0, 2)))\n",
    "    #     print('means: ', generated_data.mean(axis=(0, 2)))\n",
    "\n",
    "    #     print('min: ', ori_data.min(axis=(0, 2)))\n",
    "    #     print('min: ', generated_data.min(axis=(0, 2)))\n",
    "\n",
    "    #     print('max: ', ori_data.max(axis=(0, 2)))\n",
    "    #     print('max: ', generated_data.max(axis=(0, 2)))\n",
    "    #     sys.exit()\n",
    "    #     ---------------------------------------------------------------------------\n",
    "    #     print(\"-\"*90); print('Visualizations:')\n",
    "    #     visualization(ori_data[0:generated_data.shape[0]], generated_data, 'pca')\n",
    "    #     visualization(ori_data[0:generated_data.shape[0]], generated_data, 'tsne')\n",
    "\n",
    "        #     ---------------------------------------------------------------------------\n",
    "    #     print(\"-\"*90); print('Discrimination Score :')\n",
    "    #     discriminative_score = list()\n",
    "    #     for iter in range(metric_iteration):\n",
    "    #         temp_disc = discriminative_score_metrics(ori_data, generated_data)\n",
    "    #         discriminative_score.append(temp_disc)  \n",
    "    #         print(\"---------- done disc iter: \", iter, 'score: ', temp_disc, '----------')\n",
    "\n",
    "    #     #     ---------------------------------------------------------------------------\n",
    "    #     print(\"-\"*90); print('Discrimination Score :')\n",
    "    #     print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))\n",
    "    #     print(\"Discriminative score CI: \", confidence_interval(discriminative_score)[1])\n",
    "\n",
    "        #     ---------------------------------------------------------------------------             \n",
    "        print(\"-\"*90); print('Predictive Score :')\n",
    "        predictive_score = list()\n",
    "        for tt in range(metric_iteration):\n",
    "            temp_pred = predictive_score_metrics(ori_data, ori_data, iterations = 4000)\n",
    "            predictive_score.append(temp_pred)   \n",
    "        print('Predictive score: ' + str(np.round(np.mean(predictive_score), 4)))\n",
    "        print(\"Predictive score CI: \", confidence_interval(predictive_score)[1])\n",
    "\n",
    "        print(\"\\n\")\n",
    "        #     ---------------------------------------------------------------------------\n",
    "    #     visualization(ori_data[0:generated_data.shape[0]], generated_data, 'pca', \"sine_pca_\" + str(int(training_size)))\n",
    "    #     visualization(ori_data[0:generated_data.shape[0]], generated_data, 'tsne', \"sine_tsne_\" +str(int(training_size)))\n",
    "        \n",
    "print(\"all done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 1.15 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-1.15-cpu-py37-ubuntu18.04-v7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
