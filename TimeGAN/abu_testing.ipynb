{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install matplotlib\n",
    "#!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import sys \n",
    "import time\n",
    "\n",
    "# from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.discriminative_metrics2 import discriminative_score_metrics\n",
    "\n",
    "# from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.predictive_metrics2 import predictive_score_metrics\n",
    "\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_dir = \"../data/processed_orig_data/\"\n",
    "gen_data_dir = \"../data/generated_data/\"\n",
    "\n",
    "scores_dir = './scores/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler():\n",
    "    \"\"\"Min Max normalizer.\n",
    "    Args:\n",
    "    - data: original data\n",
    "\n",
    "    Returns:\n",
    "    - norm_data: normalized data\n",
    "    \"\"\"\n",
    "    def fit_transform(self, data): \n",
    "        self.fit(data)\n",
    "        scaled_data = self.transform(data)\n",
    "        return scaled_data\n",
    "\n",
    "\n",
    "    def fit(self, data):    \n",
    "        self.mini = np.min(data, 0)\n",
    "        self.range = np.max(data, 0) - self.mini\n",
    "        return self\n",
    "        \n",
    "\n",
    "    def transform(self, data):\n",
    "        numerator = data - self.mini\n",
    "        scaled_data = numerator / (self.range + 1e-7)\n",
    "        return scaled_data\n",
    "\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        data *= self.range\n",
    "        data += self.mini\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "metric_iteration = 2\n",
    "\n",
    "# model name\n",
    "model = 'vae_conv_I'      # vae_conv_I, vae_IN\n",
    "\n",
    "disc_epochs = 500 ; pred_epochs = 500\n",
    "\n",
    "# full selection of data to run\n",
    "training_sizes = [2, 5, 10, 20, 100]\n",
    "datasets = ['sine', 'stocks', 'energy', 'air']\n",
    "\n",
    "\n",
    "# custom selection \n",
    "# training_sizes = [ 5 ]\n",
    "# datasets = ['air']\n",
    "\n",
    "data = []\n",
    "for dataset in datasets:\n",
    "\n",
    "    for training_size in training_sizes:\n",
    "\n",
    "        print('-'*90); print('-'*90)\n",
    "        print(f\"Data: {dataset}; Training Size: {training_size}\")\n",
    "\n",
    "        ## original data \n",
    "        fname = f'{orig_data_dir + dataset}_subsampled_train_perc_{training_size}.npz'\n",
    "        loaded = np.load(fname)\n",
    "        ori_data = loaded['data']\n",
    "\n",
    "        ## generated data \n",
    "        sample_file_name = gen_data_dir + f'{model}/{model}_gen_samples_{dataset}_perc_{training_size}.npz'\n",
    "        loaded = np.load(sample_file_name)\n",
    "        gen_data = loaded['data']        \n",
    "        \n",
    "        ## scale orig and generated data\n",
    "        scaler_orig = MinMaxScaler( )  \n",
    "        scaled_ori_data = scaler_orig.fit_transform(ori_data)\n",
    "        scaled_gen_data = scaler_orig.transform(gen_data)         \n",
    "        print('ori_data shape: ', ori_data.shape, 'gen_data shape: ', gen_data.shape)\n",
    "    #     ---------------------------------------------------------------------------\n",
    "        print(\"-\"*90); print('Visualizations:')\n",
    "        # visualization(scaled_ori_data[0:scaled_gen_data.shape[0]], scaled_gen_data, 'pca')\n",
    "#         visualization(scaled_ori_data[0:scaled_gen_data.shape[0]], scaled_gen_data, 'tsne')\n",
    "\n",
    "#            ---------------------------------------------------------------------------\n",
    "        print(\"-\"*90); print('Discrimination Score :')\n",
    "        discriminative_score = list()\n",
    "        for tt in range(metric_iteration):\n",
    "            temp_disc = discriminative_score_metrics(scaled_ori_data, scaled_gen_data,  epochs = disc_epochs)\n",
    "            discriminative_score.append(temp_disc)  \n",
    "            print(\"----------  disc iter: \", tt, 'score: ', temp_disc, '----------')\n",
    "\n",
    "        disc_mean = np.round(np.mean(discriminative_score), 4)\n",
    "        disc_CI = np.round(confidence_interval(discriminative_score)[1], 4)\n",
    "        print(\"-\"*90); print('Discrimination Score :')\n",
    "        print('Discriminative score: ' + str(disc_mean))\n",
    "        print(\"Discriminative score CI: \", disc_CI)\n",
    "\n",
    "        #     ---------------------------------------------------------------------------             \n",
    "        print(\"-\"*90); print('Predictive Score :')\n",
    "        predictive_score = list()\n",
    "        for tt in range(metric_iteration):\n",
    "            temp_pred = predictive_score_metrics(scaled_ori_data, scaled_gen_data, epochs = pred_epochs)\n",
    "            predictive_score.append(temp_pred)   \n",
    "            print(\"----------  pred iter: \", tt, 'score: ', temp_pred, '----------')\n",
    "        \n",
    "        pred_mean = np.round(np.mean(predictive_score), 4)\n",
    "        pred_CI = np.round(confidence_interval(predictive_score)[1], 4)\n",
    "        print('Predictive score: ' + str(pred_mean))\n",
    "        print(\"Predictive score CI: \", pred_CI)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        #     ---------------------------------------------------------------------------\n",
    "        # save results\n",
    "        data =  [[  model,  dataset,   training_size,   metric_iteration,  \n",
    "                      disc_epochs, disc_mean,  disc_CI,  \n",
    "                      pred_epochs, pred_mean,  pred_CI  ]]\n",
    "        cols = ['model', 'dataset', 'train_perc', 'iters', \n",
    "                    'disc_epochs' , 'disc_mean', 'disc_CI', \n",
    "                    'pred_epochs', 'pred_mean', 'pred_CI']\n",
    "        df = pd.DataFrame(data, columns = cols)\n",
    "        df.to_csv(f\"./{scores_dir}/{model}_disc_and_pred_scores_{dataset}_{training_size}.csv\", index=False, float_format='%.4f')\n",
    "end = time.time()\n",
    "print(f\"Total run time: {np.round((end - start)/60.0, 2)} minutes\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all score files into single file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for dataset in datasets:\n",
    "    for training_size in training_sizes:\n",
    "        fname = f\"./{scores_dir}/{model}_disc_and_pred_scores_{dataset}_{training_size}.csv\"\n",
    "        if os.path.exists(fname):\n",
    "            data = pd.read_csv(fname)\n",
    "            all_scores.append(data)\n",
    "all_scores = pd.concat(all_scores, ignore_index=True)\n",
    "all_scores = all_scores.round(3)\n",
    "all_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores.to_csv(f\"./{scores_dir}/{model}_disc_and_pred_scores_ALL.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
