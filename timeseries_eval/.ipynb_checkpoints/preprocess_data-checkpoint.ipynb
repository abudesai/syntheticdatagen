{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = 'sine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sine_data(no, seq_len, dim):   \n",
    "    \"\"\"Sine data generation.\n",
    "    Args:\n",
    "    - no: the number of samples\n",
    "    - seq_len: sequence length of the time-series\n",
    "    - dim: feature dimensions\n",
    "\n",
    "    Returns:\n",
    "    - data: generated data\n",
    "    \"\"\" \n",
    "    size = (no, 1, dim)\n",
    "    freq = np.random.uniform(0, 1, size)    \n",
    "    phase = np.random.uniform(-1, 1, size)\n",
    "    \n",
    "    seq = np.arange(seq_len)\n",
    "    seq = np.expand_dims(seq, axis=0)\n",
    "    seq = np.expand_dims(seq, axis=-1)\n",
    "    \n",
    "    data = np.sin(freq * seq + phase)    \n",
    "#     data = (data + 1) * 0.5\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, T, D = 10000, 24, 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PERC = 0.05\n",
    "TRAIN_PERC = 1- TEST_PERC\n",
    "\n",
    "perc_of_train_data = [2, 5, 10, 20, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\\sine_subsampled_train_perc_2.npy\n",
      "./data\\sine_subsampled_train_perc_5.npy\n",
      "./data\\sine_subsampled_train_perc_10.npy\n",
      "./data\\sine_subsampled_train_perc_20.npy\n",
      "./data\\sine_subsampled_train_perc_100.npy\n"
     ]
    }
   ],
   "source": [
    "# sine_datasets = []\n",
    "for p in perc_of_train_data:\n",
    "    N_small = int(N * p / 100)\n",
    "    sine_data = gen_sine_data(N_small, T, D)\n",
    "    sine_data = np.array(sine_data)\n",
    "    \n",
    "    np.random.shuffle(sine_data)    \n",
    "    #print(sine_data.shape)\n",
    "    \n",
    "    fname = f'{selected}_subsampled_train_perc_{p}.npy'\n",
    "    full_path = os.path.join(data_dir, fname)\n",
    "    print(full_path)\n",
    "    \n",
    "    np.save(full_path, sine_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy and Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'energy': {\n",
    "        'file': 'Energy-energydata_complete.csv',\n",
    "        'time_col': 'date',\n",
    "    },\n",
    "    'stocks': {\n",
    "        'file': 'stock_data.csv',\n",
    "        'time_col': None, \n",
    "    },\n",
    "    'airquality': {\n",
    "        'file': 'AirQualityUCI.csv',\n",
    "        'time_col': 'date',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected = 'energy'\n",
    "selected = 'stocks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Open       High        Low      Close  Adj_Close    Volume\n",
      "0  49.676899  51.693783  47.669952  49.845802  49.845802  44994500\n",
      "1  50.178635  54.187561  49.925285  53.805050  53.805050  23005800\n",
      "2  55.017166  56.373344  54.172661  54.346527  54.346527  18393200\n",
      "3  55.260582  55.439419  51.450363  52.096165  52.096165  15361800\n",
      "4  52.140873  53.651051  51.604362  52.657513  52.657513   9257400\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(data_dir, data_dict[selected]['file'])\n",
    "\n",
    "if data_dict[selected]['time_col'] is not None: \n",
    "    data = pd.read_csv(file_path, parse_dates=[data_dict[selected]['time_col']])\n",
    "else:\n",
    "    data = pd.read_csv(file_path)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (3685, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort data by time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "time_col = data_dict[selected]['time_col']\n",
    "print(time_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_col in data: \n",
    "    data.sort_values(by=time_col, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the time col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (3685, 6)\n"
     ]
    }
   ],
   "source": [
    "if time_col in data: del data[time_col]\n",
    "print(\"data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frac:20%, train_data_frac shape: (700, 6)\n"
     ]
    }
   ],
   "source": [
    "N = data.shape[0]\n",
    "\n",
    "frac_datasets = []\n",
    "for p in perc_of_train_data: \n",
    "    \n",
    "    num_test = int(N * TEST_PERC)   # to be held-out\n",
    "    orig_num_train = N - num_test\n",
    "    \n",
    "    test_data = data.tail(num_test)  # to be used for evaluation later\n",
    "    \n",
    "    orig_train_data = data.loc[np.arange(orig_num_train)]\n",
    "    #print(orig_train_data.shape)\n",
    "    \n",
    "    num_train_frac = int(orig_num_train * p / 100.)\n",
    "    #print(f'Num train steps for p = {p} is {num_train_frac}')\n",
    "    \n",
    "    train_data_frac = data.tail(num_train_frac) \n",
    "    frac_datasets.append(train_data_frac)\n",
    "    print(f'frac:{p}%, train_data_frac shape: {train_data_frac.shape}' )\n",
    "    \n",
    "    #np.save(os.path.join(data_dir, f'{selected}_train_perc_{p}.npy'), train_data_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to 3D tensors\n",
    "shape = N, T, D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaped:  (1, 700, 6)\n"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(frac_datasets):\n",
    "    frac_datasets[i] = d.values.reshape(1, *d.shape)\n",
    "    print(\"reshaped: \", frac_datasets[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Subsampled series of required seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 20 3d tensor shape: (676, 24, 6)\n"
     ]
    }
   ],
   "source": [
    "target_len = 24\n",
    "for p, d in zip(perc_of_train_data, frac_datasets):\n",
    "    subsampled_dataset = []\n",
    "    for idx in range(d.shape[1] - T):\n",
    "        ser = d[:, idx: idx+T, :]\n",
    "        subsampled_dataset.append(ser)\n",
    "    subsampled_dataset = np.concatenate(subsampled_dataset, axis=0)\n",
    "    print('p:', p, '3d tensor shape:', subsampled_dataset.shape)\n",
    "    \n",
    "    np.save(os.path.join(data_dir, f'{selected}_subsampled_train_perc_{p}.npy'), subsampled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
